{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stuckic/posCimatec/blob/main/20230830_Atividade_Altura_Peso_Genero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYlozs4TdnSl"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK8ibA5tdpqV"
      },
      "outputs": [],
      "source": [
        "# Passo 1: Carregamento do csv\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SA-ukRJeSF7"
      },
      "outputs": [],
      "source": [
        "# Passo 2: Ler os dados usando o pandas\n",
        "file_name = next(iter(uploaded))\n",
        "\n",
        "# file_name = f'D:\\Downloads\\Altura, Peso, Gênero.csv'\n",
        "data = pd.read_csv(file_name, sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjnU5kXhevUi"
      },
      "outputs": [],
      "source": [
        "# Label\n",
        "data['Label'] = data.iloc[:, 3].apply(lambda x: 1 if x == 'Masculino' else 0)\n",
        "\n",
        "# Correções do data set\n",
        "data.iloc[:, 1:3] = data.iloc[:, 1:3].replace('175', '1,75', regex= True)\n",
        "data.iloc[:, 1:3] = data.iloc[:, 1:3].replace(',', '.', regex= True)\n",
        "data.iloc[:, 1:3] = data.iloc[:, 1:3].replace('kg', '', regex= True)\n",
        "\n",
        "# Numeralização\n",
        "data.iloc[:, 1:3] = data.iloc[:, 1:3].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSjAqe4OocJG"
      },
      "outputs": [],
      "source": [
        "# Mapear rótulos para cores\n",
        "label_to_color = {\n",
        "    'Feminino': 'red',\n",
        "    'Masculino': 'blue'\n",
        "}\n",
        "\n",
        "# Criar uma lista de cores com base nos rótulos\n",
        "point_colors = [label_to_color[label] for label in data.iloc[:, 3]]\n",
        "\n",
        "# Criar um scatter plot usando os dados do DataFrame e as cores mapeadas\n",
        "x1 = data.iloc[:, 1]\n",
        "x2 = data.iloc[:, 2]\n",
        "\n",
        "# Criar um scatter plot usando os dados do DataFrame e as cores mapeadas\n",
        "scatter = plt.scatter(x1, x2, c=point_colors, cmap='coolwarm')\n",
        "\n",
        "# Criar artistas para a legenda\n",
        "legend_labels = list(label_to_color.keys())  # Usar as chaves do dicionário como rótulos da legenda\n",
        "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=label_to_color[label], markersize=10, label=label) for label in legend_labels]\n",
        "\n",
        "# Adicionar a legenda\n",
        "plt.legend(handles=legend_handles)\n",
        "\n",
        "# Adicionar rótulos e título\n",
        "plt.xlabel('Altura')\n",
        "plt.ylabel('Peso')\n",
        "plt.title('Gráfico de Dispersão')\n",
        "\n",
        "# Mostrar o gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gveF7-VCocJH"
      },
      "outputs": [],
      "source": [
        "# Balanceamento\n",
        "categorias_list = list(data.iloc[:, 3].value_counts().index)\n",
        "valores_list = list(data.iloc[:, 3].value_counts().values)\n",
        "total = sum(valores_list)\n",
        "for i in range(len(categorias_list)):\n",
        "    print(f'{categorias_list[i]}: {valores_list[i]} - {round(valores_list[i]/total*100, 1)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBBgx0uTgMaS"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas do SVM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfdfTKococJI"
      },
      "outputs": [],
      "source": [
        "# Separação dos dados em X e y\n",
        "X = data.iloc[:, 1:3].values\n",
        "y = data.iloc[:, 4].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JedNcv6nocJJ"
      },
      "outputs": [],
      "source": [
        "# Teste e treino\n",
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(X, y, test_size=0.2, random_state=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X71pXZyvocJJ"
      },
      "outputs": [],
      "source": [
        "# Normalização\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_train = scaler.fit_transform(X_train0)\n",
        "X_test = scaler.transform(X_test0)\n",
        "y_train = y_train0\n",
        "y_test  = y_test0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVQCBgDxocJK"
      },
      "source": [
        "## Regressão Logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqGnsg5iocJL"
      },
      "outputs": [],
      "source": [
        "# Regressão logística padrão\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "# Predição dos dados de test\n",
        "y_pred = model_lr.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g16zNbGgocJL"
      },
      "outputs": [],
      "source": [
        "# Cálculo da acurácia\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUsGmv6yocJL"
      },
      "outputs": [],
      "source": [
        "# Nova instância\n",
        "x_new = scaler.transform(np.array([[1.74, 80]]))\n",
        "x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcPz6ucbocJL"
      },
      "outputs": [],
      "source": [
        "# Predição nova instância\n",
        "model_lr.predict(x_new)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw72TnESocJL"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpAvHJQyhDml"
      },
      "outputs": [],
      "source": [
        "# Criação da instância\n",
        "model_knn = KNeighborsClassifier()\n",
        "model_knn.fit(X_train, y_train)\n",
        "\n",
        "# Predição dos dados de test\n",
        "y_pred = model_knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtAdZzZvhNRq"
      },
      "outputs": [],
      "source": [
        "# Cálculo da acurácia\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8gUkfAfhXIL"
      },
      "outputs": [],
      "source": [
        "# Nova instância\n",
        "x_new = scaler.transform(np.array([[1.74, 80]]))\n",
        "x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_-mkyp6lf0q"
      },
      "outputs": [],
      "source": [
        "# Predição nova instância\n",
        "model_knn.predict(x_new)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jalftq4uocJM"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundary(estimator, X, y):\n",
        "    X_color = X\n",
        "    y_color = np.vectorize(lambda r: 'red' if r == 0 else 'blue')(y)\n",
        "    x_axis, y_axis = np.arange(-.5, 1.5, .005), np.arange(-.5, 1.5, .005)\n",
        "    xx, yy = np.meshgrid(x_axis, y_axis)\n",
        "    xx_ravel = xx.ravel()\n",
        "    yy_ravel = yy.ravel()\n",
        "    X_grid = pd.DataFrame([xx_ravel, yy_ravel]).T\n",
        "    y_grid_predictions = estimator.predict(X_grid)\n",
        "    y_grid_predictions = y_grid_predictions.reshape(xx.shape)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.contourf(xx, yy, y_grid_predictions, cmap=plt.cm.autumn_r, alpha=.3)\n",
        "    ax.scatter(X_color[:, 0], X_color[:, 1], color=y_color, alpha=1)\n",
        "    ax.set(\n",
        "        xlabel= 'Altura',\n",
        "        ylabel= 'Peso',\n",
        "        title=str(estimator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_ysE56YocJM"
      },
      "outputs": [],
      "source": [
        "# Chart com os dados de Treino - lr\n",
        "plot_decision_boundary(model_lr, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOEqErfHocJM"
      },
      "outputs": [],
      "source": [
        "# Chart com os dados de Treino - knn\n",
        "plot_decision_boundary(model_knn, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axID30qMocJM"
      },
      "outputs": [],
      "source": [
        "# Chart com os dados de Test - lr\n",
        "plot_decision_boundary(model_lr, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3NEAYeOocJN"
      },
      "outputs": [],
      "source": [
        "# Chart com os dados de Test - Knn\n",
        "plot_decision_boundary(model_knn, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wohgHXPqocJN"
      },
      "source": [
        "## Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wndfzVweocJN"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0IyvI6_ocJN"
      },
      "outputs": [],
      "source": [
        "# Montagem do modelo\n",
        "model_mlp = Sequential()\n",
        "\n",
        "# Layer de tamanho 32 e 2 atributos (altura e peso)\n",
        "model_mlp.add(Dense(8, input_shape=(2,), activation='tanh'))\n",
        "model_mlp.add(Dense(8, activation='sigmoid'))\n",
        "# Layer de saída\n",
        "model_mlp.add(Dense(2, activation='softmax'))\n",
        "model_mlp.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q5hLkReocJN"
      },
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "epochs = 100\n",
        "\n",
        "history = model_mlp.fit(X_train, y_train,\n",
        "                        batch_size= batch_size,\n",
        "                        epochs= epochs,\n",
        "                        verbose= 1,\n",
        "                        validation_split= 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFATIZ6kocJN"
      },
      "outputs": [],
      "source": [
        "# Plotando o historico do processo de treinamento\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(history.history['loss'], color='blue')\n",
        "plt.plot(history.history['val_loss'], color='red')\n",
        "plt.title('Model loss', fontsize=20)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Treinamento', 'Validação'], loc='upper right', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5qUwBRWocJN"
      },
      "outputs": [],
      "source": [
        "# Avaliação\n",
        "score = model_mlp.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQwzNsCXocJO"
      },
      "outputs": [],
      "source": [
        "# Nova instância\n",
        "x_new = scaler.transform(np.array([[1.74, 80]]))\n",
        "x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9pi-YjRocJO"
      },
      "outputs": [],
      "source": [
        "# Predição nova instância\n",
        "result = model_mlp.predict(x_new)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8h2q4LfocJO"
      },
      "outputs": [],
      "source": [
        "# Resultado é o índice do vetor com o valor maior\n",
        "np.argmax(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTODMBSDocJO"
      },
      "outputs": [],
      "source": [
        "np.array(np.argmax(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C7GUVAGocJO"
      },
      "outputs": [],
      "source": [
        "# Adaptação do predict\n",
        "\n",
        "class Onehot2Int(object):\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "    def predict(self, X):\n",
        "        y_pred = self.model.predict(X)\n",
        "        return np.array(np.argmax(y_pred, axis=1))\n",
        "\n",
        "model_mlp1=Onehot2Int(model_mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0QYNyZ1ocJO"
      },
      "outputs": [],
      "source": [
        "# Chart com os dados de Train - MLP\n",
        "plot_decision_boundary(model_mlp1, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2iT6gKoocJO"
      },
      "outputs": [],
      "source": [
        "# Chart com os dados de Test - MLP\n",
        "plot_decision_boundary(model_mlp1, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_rYiqdzocJP"
      },
      "source": [
        "## Trabalho\n",
        "\n",
        "Repita o mesmo procedimento feito até aqui para o Perceptron Simples criado por vocês na atividade anterior. Implemente uma classe com os métodos fit, predict e evaluate (apenas para a acurácia).\n",
        "\n",
        "Tente melhorar o desempenho dos modelos ajustando os hiperparâmetros. No caso do MLP, procure fazer com que não haja overfitting/underfitting, enquanto mantém a acurácia mais alta possível, e o loss mais baixo possível (dilema viés-variância).\n",
        "\n",
        "Ao final, compare os resultados de todos os modelos, usando uma tabela para resumir o que encontrou. Discuta os resultados analisando os pontos fortes e fracos de cada um."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOGMVl1KocJP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp8R_cd8ocJP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}